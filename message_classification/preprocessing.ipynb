{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick note about Jupyter cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are editing a cell in Jupyter notebook, you need to re-run the cell by pressing `<Shift> + <Enter>`. This will allow changes you made to be available to other cells.\n",
    "\n",
    "Use `<Enter>` to make new lines inside a cell you are editing.\n",
    "\n",
    "### Code cells\n",
    "Re-running will execute any statements you have written. To edit an existing code cell, click on it.\n",
    "\n",
    "### Markdown cells\n",
    "Re-running will render the markdown text. To edit an existing markdown cell, double-click on it.\n",
    "\n",
    "\n",
    "### Common Jupyter operations\n",
    "\n",
    "**Inserting and removing cells**\n",
    "\n",
    "Use the \"plus sign\" icon to insert a cell below the currently selected cell\n",
    "Use \"Insert\" -> \"Insert Cell Above\" from the menu to insert above\n",
    "\n",
    "**Clear the output of all cells**\n",
    "\n",
    "Use \"Kernel\" -> \"Restart\" from the menu to restart the kernel\n",
    "click on \"clear all outputs & restart\" to have all the output cleared\n",
    "\n",
    "**Show function signature**\n",
    "\n",
    "Start typing function and hit `<Shift> + <Tab>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## import necessary libraries\n",
    "\n",
    "Import the following packages: `pandas as pd`, `csv`, `nltk` and `matplotlib.pyplot as plt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import nltk \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "\n",
    "As we have done the step of collecting some sample data for you already, you only have to load the data into a pandas dataframe using the method `pd.read_csv()`. Typing a variable name into a jupyter cell and running it, shows you the current content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets = pd.read_csv('data\\\\tweets\\\\tweets.tsv', sep='\\t', header=None, names=[\"id\", \"sentiment\",\"md5\",\"related\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect and clean data\n",
    "\n",
    "The dataset contains several entries of messages that have been deleted by the user after posting them, use pandas' `str.contains()` or any other method like `loc` to remove all rows that represent a message not accessibly anymore (\"Not Available\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "tweets = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns we are most interested in are \"text\" and \"sentiment\". Use pandas' `groupby()` method in combination with `count()` to get a first notion about the distribution of our labels. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5838378833ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tweets' is not defined"
     ]
    }
   ],
   "source": [
    "tweets.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the unnecessary columns to retain a dataframe with the two columns \"text\" and \"sentiment\".\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "tweets = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the pandas function `str.replace()` to get rid of [twitter handles](https://www.urbandictionary.com/define.php?term=twitter%20handle) (hint: use regular expressions with `r'my_regex'` as the first argument `in str.replace()`). Example to remove all numbers: `data['column'].str.replace(r'[0-9]+')`\n",
    "\n",
    "infos on how to build regular expressions: https://www.rexegg.com/regex-quickstart.html#quantifiers\n",
    "\n",
    "test your regular expressions: https://regex101.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "tweets['text'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced**\n",
    "- Get rid of links. \n",
    "- Inspect the rest of the columns and keep some if they might contain information relevant to our prediction at a later stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "tweets['text'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create single string to count word frequencies \n",
    "\n",
    "In order to visualize word frequencies, we will concatenate all messages to create one long string containing all words present in these messages. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "merged_tweets  = tweets.text.str.cat(sep=' ')\n",
    "merged_tweets_tokens = word_tokenize(merged_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot token frequencies\n",
    "plt.figure(figsize=(15, 8))  \n",
    "\n",
    "fd = nltk.FreqDist(merged_tweets_tokens)\n",
    "fd.plot(50,cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If you still have symbols or words that seem unnecessary for the classification ->  jump back up and replace them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the pandas `to_csv()` method to save your dataframe as a .csv file. Name it \"training_data_tweets.csv\", set `encoding='utf-8'`, use `quoting=csv.QUOTE_ALL`, `header=False` and `index=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe in a format you can easily import in the following notebook\n",
    "tweets.to_csv(\"training_data_tweets.csv\", encoding='utf-8', quoting=csv.QUOTE_ALL,header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
